# ========== æ ¸å¿ƒä¿®å¤ï¼šæŒ‡å®šGradioæœ¬åœ°ä¸´æ—¶ç›®å½•ï¼Œè§£å†³PermissionErroræƒé™é—®é¢˜ ==========
import os
import tempfile

# ä¸´æ—¶æ–‡ä»¶å­˜é¡¹ç›®å†…çš„gradio_tempæ–‡ä»¶å¤¹ï¼Œé¿å¼€ç³»ç»Ÿæƒé™ç›®å½•ï¼Œè‡ªåŠ¨åˆ›å»º
os.environ['GRADIO_TEMP_DIR'] = os.path.join(os.path.dirname(__file__), "gradio_temp")
os.makedirs(os.environ['GRADIO_TEMP_DIR'], exist_ok=True)
# ==================================================================================

# ===================== å‰ç½®è¡¥ä¸+ä¾èµ–å¯¼å…¥ =====================
import PIL.Image as Image

if not hasattr(Image, 'ANTIALIAS'):
    Image.ANTIALIAS = Image.LANCZOS

# æ ¸å¿ƒä¾èµ–ï¼ˆä»…ä¿ç•™åŸºç¡€å¿…ç”¨ï¼‰
import librosa
import numpy as np
import gradio as gr
import shutil
import uuid
from moviepy.editor import ImageClip, AudioFileClip, CompositeVideoClip, concatenate_videoclips
from PIL import ImageDraw, ImageFont

# ç¡®ä¿é¡¹ç›®å†…ä¸´æ—¶ç›®å½•å­˜åœ¨ï¼ˆè‡ªåŠ¨åˆ›å»ºï¼‰
os.makedirs("temp_output", exist_ok=True)
os.makedirs("temp_text", exist_ok=True)
os.makedirs("temp_subtitles", exist_ok=True)
os.makedirs("temp_audio", exist_ok=True)

# å…¨å±€å˜é‡ï¼ˆä»…ä¿ç•™è§†é¢‘è·¯å¾„ï¼Œæç®€ï¼‰
generated_video_path = None


# ===================== æ ¸å¿ƒå·¥å…·å‡½æ•°ï¼ˆå®Œå…¨ä¿ç•™ï¼ŒåŠŸèƒ½ä¸å˜ï¼‰ =====================
def parse_pos(pos_str, base_size, elem_size=0, is_x=True):
    """è§£æä½ç½®ï¼šç²¾å‡†å±…ä¸­è®¡ç®—ï¼ˆæ ¸å¿ƒä¿ç•™ï¼‰"""
    pos_str = pos_str.strip().lower()
    if pos_str.isdigit():
        return int(pos_str)
    key = ""
    offset = 0
    for i, c in enumerate(pos_str):
        if c.isdigit():
            key = pos_str[:i]
            offset = int(pos_str[i:])
            break
    if not key:
        key = pos_str

    if key == "center":
        return (base_size / 2) - (elem_size / 2)
    if is_x:
        if key == "left":
            return offset
        elif key == "right":
            return base_size - offset - elem_size
        else:
            return offset
    else:
        if key == "top":
            return offset
        elif key == "bottom":
            return base_size - offset - elem_size
        else:
            return offset


def parse_color(color_str):
    """è§£æé¢œè‰²ï¼š#FFFFFF/red/rgbç­‰ï¼ˆæ ¸å¿ƒä¿ç•™ï¼‰"""
    color_str = color_str.strip().lower()
    preset_colors = {
        "white": (255, 255, 255), "black": (0, 0, 0), "red": (255, 0, 0),
        "green": (0, 255, 0), "blue": (0, 0, 255), "yellow": (255, 255, 0),
        "orange": (255, 165, 0), "purple": (128, 0, 128), "gray": (128, 128, 128)
    }
    if color_str in preset_colors:
        return preset_colors[color_str]
    try:
        hex_color = color_str.lstrip('#')
        if len(hex_color) == 6:
            return (int(hex_color[0:2], 16), int(hex_color[2:4], 16), int(hex_color[4:6], 16))
    except:
        pass
    try:
        if color_str.startswith("rgb(") and color_str.endswith(")"):
            rgb_part = color_str[4:-1].split(",")
            return (int(rgb_part[0].strip()), int(rgb_part[1].strip()), int(rgb_part[2].strip()))
    except:
        pass
    return (255, 255, 255)


def detect_voice_segments(audio_path, threshold=0.02, min_duration=0.3):
    """è¯­éŸ³æ®µæ£€æµ‹ï¼ˆæ ¸å¿ƒä¿ç•™ï¼Œä½ çš„12æ®µè¯­éŸ³æ­£å¸¸æ£€æµ‹ï¼‰"""
    if not os.path.exists(audio_path):
        return "âŒ éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·é‡æ–°ä¸Šä¼ ï¼", []
    y, sr = librosa.load(audio_path, sr=None)
    frame_length = 2048
    hop_length = 512
    energy = librosa.feature.rms(y=y, frame_length=frame_length, hop_length=hop_length)[0]
    times = librosa.times_like(energy, sr=sr, hop_length=hop_length)
    voice_frames = energy > threshold
    segments = []
    start = None
    for i, is_voice in enumerate(voice_frames):
        if is_voice and start is None:
            start = times[i]
        elif not is_voice and start is not None:
            end = times[i]
            if end - start >= min_duration:
                segments.append((round(start, 2), round(end, 2)))
            start = None
    if start is not None:
        end = times[-1]
        if end - start >= min_duration:
            segments.append((round(start, 2), round(end, 2)))
    # åˆå¹¶ç›¸é‚»çŸ­è¯­éŸ³æ®µ
    final_segments = []
    for seg in segments:
        if not final_segments:
            final_segments.append(seg)
        else:
            last_s, last_e = final_segments[-1]
            if seg[0] - last_e < 0.2:
                final_segments[-1] = (last_s, seg[1])
            else:
                final_segments.append(seg)
    if not final_segments:
        return "âŒ æœªæ£€æµ‹åˆ°è¯­éŸ³ï¼Œè¯·è°ƒä½é˜ˆå€¼é‡è¯•ï¼", []
    # æ ¼å¼åŒ–æ£€æµ‹ç»“æœ
    tip = f"âœ… æ£€æµ‹åˆ°{len(final_segments)}ä¸ªè¯­éŸ³æ®µï¼š\n"
    for i, (s, e) in enumerate(final_segments, 1):
        tip += f"{i}. {s}ç§’ â†’ {e}ç§’ï¼ˆæ—¶é•¿ï¼š{e - s:.2f}ç§’ï¼‰\n"
    tip += "\nğŸ’¡ è¯·æŒ‰è¯­éŸ³æ®µæ•°è¾“å…¥å¯¹åº”è¡Œæ•°çš„çº¯å­—å¹•ï¼"
    return tip, final_segments


def match_subtitle_with_voice(subtitle_text, voice_segments, start_offset=0.0, end_offset=0.0):
    """å­—å¹•åŒ¹é…è¯­éŸ³æ®µï¼ˆæ ¸å¿ƒä¿ç•™ï¼Œæ—¶é—´è½´é˜²é‡å ï¼‰"""
    if not voice_segments:
        return "âŒ è¯·å…ˆæ£€æµ‹è¯­éŸ³æ®µï¼"
    subtitle_lines = [line.strip() for line in subtitle_text.strip().split("\n") if line.strip()]
    if not subtitle_lines:
        return "âŒ è¯·è¾“å…¥çº¯å­—å¹•æ–‡æœ¬ï¼ˆæ¯è¡Œä¸€æ®µï¼‰ï¼"

    matched_lines = []
    last_end_time = 0.0
    for i, line in enumerate(subtitle_lines):
        if i < len(voice_segments):
            s, e = voice_segments[i]
            s = round(s + start_offset, 2)
            e = round(e + end_offset, 2)
            s = max(0.0, s)
            s = max(s, last_end_time)  # å¼ºåˆ¶é˜²é‡å 
            e = max(s + 0.5, e)  # æœ€å°æ—¶é•¿0.5ç§’
        else:
            # å­—å¹•è¡Œæ•°è¶…è¯­éŸ³æ®µï¼Œè‡ªåŠ¨ç”Ÿæˆè¿ç»­æ—¶é—´
            avg_dur = np.mean([e - s for s, e in voice_segments]) if voice_segments else 3.0
            s = round(last_end_time, 2)
            e = round(s + avg_dur, 2)
        last_end_time = e
        # ç”Ÿæˆæ ‡å‡†æ ¼å¼å­—å¹•
        matched_lines.append(f"{s},{line},{e},36,#FFFFFF,center,bottom100")
    return "\n".join(matched_lines)


def parse_subtitles(subtitle_text, video_w, video_h):
    """è§£æå­—å¹•é…ç½®ï¼ˆæ ¸å¿ƒä¿ç•™ï¼‰"""
    subtitles = []
    if not subtitle_text.strip():
        return subtitles
    lines = subtitle_text.strip().split("\n")
    for idx, line in enumerate(lines):
        line = line.strip()
        if not line:
            continue
        try:
            parts = line.split(",")
            pos_y_str = parts[-1].strip() if len(parts) >= 1 else "bottom100"
            pos_x_str = parts[-2].strip() if len(parts) >= 2 else "center"
            color_str = parts[-3].strip() if len(parts) >= 3 else "#FFFFFF"
            font_size_str = parts[-4].strip() if len(parts) >= 4 else "36"
            end_time_str = parts[-5].strip() if len(parts) >= 5 else "0"
            content_parts = parts[1:-5] if len(parts) >= 6 else [f"å­—å¹•{idx + 1}"]
            start_time_str = parts[0].strip() if len(parts) >= 6 else "0"

            start_time = float(start_time_str) if start_time_str else 0.0
            end_time = float(end_time_str) if end_time_str else 0.0
            start_time = max(0.0, round(start_time, 2))
            end_time = max(start_time + 0.5, round(end_time, 2))

            font_size = int(font_size_str) if font_size_str.isdigit() else 36
            font_size = max(10, min(100, font_size))

            content = ",".join([p.strip() for p in content_parts]).strip() or f"å­—å¹•{idx + 1}"
            color = parse_color(color_str)

            subtitles.append({
                "start": start_time, "end": end_time, "content": content,
                "font_size": font_size, "color": color,
                "pos_x_str": pos_x_str, "pos_y_str": pos_y_str
            })
        except Exception as e:
            raise gr.Error(
                f"ç¬¬{idx + 1}è¡Œå­—å¹•è§£æå¤±è´¥ï¼š{str(e)}\nâœ… æ­£ç¡®æ ¼å¼ï¼š0.0,ä½ å¥½ä¸–ç•Œ,3.0,36,#FFFFFF,center,bottom100")
    return subtitles


def create_text_image(text, size, color, bg_color=(0, 0, 0, 0)):
    """ç”Ÿæˆå­—å¹•/æ–‡å­—å›¾ç‰‡ï¼ˆæ ¸å¿ƒä¿ç•™ï¼Œç²¾å‡†å±…ä¸­ï¼‰"""
    try:
        # å…¼å®¹Windows/Mac/Linuxå­—ä½“
        font_paths = [
            "C:/Windows/Fonts/simhei.ttf",  # Windowsé»‘ä½“
            "C:/Windows/Fonts/msyh.ttc",  # å¾®è½¯é›…é»‘
            "/Library/Fonts/Arial.ttf",  # Mac
            "/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf"  # Linux
        ]
        font = None
        for font_path in font_paths:
            if os.path.exists(font_path):
                try:
                    font = ImageFont.truetype(font_path, size)
                    break
                except:
                    continue
        if font is None:
            font = ImageFont.load_default()
        # è®¡ç®—æ–‡å­—å®½é«˜ï¼ˆå…¼å®¹æ–°æ—§PILï¼‰
        dummy_img = Image.new('RGBA', (1, 1), bg_color)
        draw = ImageDraw.Draw(dummy_img)
        try:
            bbox = draw.textbbox((0, 0), text, font=font)
            w, h = bbox[2] - bbox[0], bbox[3] - bbox[1]
        except:
            w, h = draw.textsize(text, font=font)
        # ç”Ÿæˆé€æ˜èƒŒæ™¯æ–‡å­—å›¾ç‰‡
        img = Image.new('RGBA', (w, h), bg_color)
        draw = ImageDraw.Draw(img)
        draw.text((0, 0), text, font=font, fill=color)
        temp_path = os.path.join("temp_text", f"text_{uuid.uuid4()}.png")
        img.save(temp_path, format='PNG')
        return temp_path, w, h
    except Exception as e:
        raise Exception(f"æ–‡å­—ç”Ÿæˆå¤±è´¥ï¼š{str(e)}")


def create_slideshow_clip(img_paths, duration, slide_duration=3.0):
    """å¤šå¼ èƒŒæ™¯å›¾è½®æ’­æ ¸å¿ƒå‡½æ•°ï¼ˆå®Œå…¨ä¿ç•™ï¼Œä½ çš„æ ¸å¿ƒéœ€æ±‚ï¼‰"""
    if len(img_paths) == 0:
        raise Exception("âŒ è¯·è‡³å°‘ä¸Šä¼ ä¸€å¼ èƒŒæ™¯å›¾ï¼")
    if len(img_paths) == 1:
        # å•å¼ å›¾ç›´æ¥æ˜¾ç¤ºå…¨ç¨‹
        return ImageClip(img_paths[0]).set_duration(duration)

    # å¤šå¼ å›¾è‡ªåŠ¨å‡åˆ†æ—¶é•¿ï¼Œæœ€åä¸€å¼ è¡¥å…¨å‰©ä½™æ—¶é—´ï¼Œé¿å…æ—¶é•¿ä¸åŒ¹é…
    num_imgs = len(img_paths)
    base_duration = duration / num_imgs
    clip_list = []
    remaining_duration = duration

    for i, img_path in enumerate(img_paths):
        if i == num_imgs - 1:
            img_dur = remaining_duration
        else:
            img_dur = min(base_duration, slide_duration)
            remaining_duration -= img_dur

        img_clip = ImageClip(img_path).set_duration(img_dur)
        clip_list.append(img_clip)

    # æ‹¼æ¥è½®æ’­å‰ªè¾‘ï¼Œå…¼å®¹ä¸åŒå°ºå¯¸å›¾ç‰‡
    slideshow_clip = concatenate_videoclips(clip_list, method="compose")
    return slideshow_clip


def mp3_images_to_mp4(mp3_path, img_paths, slide_duration, text="", text_size=30, text_color="#FFFFFF",
                      text_pos="center,80", watermark_path=None, watermark_alpha=0.5,
                      watermark_pos="right20,bottom20", subtitle_text=""):
    """æ ¸å¿ƒåˆæˆï¼šMP3+å¤šå¼ èƒŒæ™¯è½®æ’­+å­—å¹•+æ°´å°ï¼ˆä½ çš„æ ¸å¿ƒéœ€æ±‚ï¼‰"""
    global generated_video_path
    temp_files = []
    try:
        # åŸºç¡€æ ¡éªŒ
        if not os.path.exists(mp3_path):
            raise Exception(f"âŒ MP3æ–‡ä»¶ä¸å­˜åœ¨ï¼š{mp3_path}")
        if not img_paths or len(img_paths) == 0:
            raise Exception("âŒ è¯·è‡³å°‘ä¸Šä¼ ä¸€å¼ èƒŒæ™¯å›¾ï¼")

        # åŠ è½½éŸ³é¢‘ï¼Œè·å–æ€»æ—¶é•¿
        audio = AudioFileClip(mp3_path)
        audio_duration = audio.duration

        # 1. åˆ›å»ºèƒŒæ™¯è½®æ’­å‰ªè¾‘ï¼ˆæ ¸å¿ƒåŠŸèƒ½ï¼Œå¤šå¼ å›¾è‡ªåŠ¨åˆ‡æ¢ï¼‰
        bg_clip = create_slideshow_clip(img_paths, audio_duration, slide_duration)
        vid_w, vid_h = bg_clip.size

        # 2. ç”Ÿæˆå…¨å±€æ–‡å­—ï¼ˆå…¨ç¨‹æ˜¾ç¤ºï¼‰
        main_text_clip = None
        if text.strip():
            rgb = parse_color(text_color)
            text_img_path, text_w, text_h = create_text_image(text, text_size, rgb)
            temp_files.append(text_img_path)
            main_text_clip = ImageClip(text_img_path).set_duration(audio_duration)
            tx_str, ty_str = text_pos.split(",") if "," in text_pos else (text_pos, "0")
            tx = parse_pos(tx_str, vid_w, text_w, is_x=True)
            ty = parse_pos(ty_str, vid_h, text_h, is_x=False)
            main_text_clip = main_text_clip.set_position((tx, ty))

        # 3. ç”Ÿæˆæ°´å°ï¼ˆå¯é€‰ï¼‰
        watermark_clip = None
        if watermark_path and os.path.exists(watermark_path):
            wm_img = Image.open(watermark_path)
            w, h = wm_img.size
            # ç­‰æ¯”ä¾‹ç¼©æ”¾æ°´å°åˆ°é«˜åº¦80px
            new_w = int(w * (80 / h))
            new_h = 80
            wm_img_resized = wm_img.resize((new_w, new_h),
                                           Image.LANCZOS if hasattr(Image, 'LANCZOS') else Image.BILINEAR)
            wm_temp = os.path.join("temp_subtitles", f"wm_{uuid.uuid4()}.png")
            temp_files.append(wm_temp)
            wm_img_resized.save(wm_temp)
            # ç”Ÿæˆæ°´å°å‰ªè¾‘
            watermark_clip = ImageClip(wm_temp).set_opacity(watermark_alpha).set_duration(audio_duration)
            wx_str, wy_str = watermark_pos.split(",") if "," in watermark_pos else (watermark_pos, "0")
            wx = parse_pos(wx_str, vid_w, new_w, is_x=True)
            wy = parse_pos(wy_str, vid_h, new_h, is_x=False)
            watermark_clip = watermark_clip.set_position((wx, wy))

        # 4. ç”Ÿæˆç²¾å‡†å­—å¹•ï¼ˆæ—¶é—´è½´é˜²é‡å ï¼Œå±…ä¸­æ˜¾ç¤ºï¼‰
        subtitle_clips = []
        if subtitle_text.strip():
            subtitles = parse_subtitles(subtitle_text, vid_w, vid_h)
            for sub in subtitles:
                if sub["end"] > audio_duration:
                    sub["end"] = audio_duration
                # ç”Ÿæˆå­—å¹•å›¾ç‰‡
                sub_img_path, sub_w, sub_h = create_text_image(sub["content"], sub["font_size"], sub["color"])
                temp_files.append(sub_img_path)
                # ç”Ÿæˆå­—å¹•å‰ªè¾‘
                sub_clip = ImageClip(sub_img_path).set_duration(sub["end"] - sub["start"])
                sub_x = parse_pos(sub["pos_x_str"], vid_w, sub_w, is_x=True)
                sub_y = parse_pos(sub["pos_y_str"], vid_h, sub_h, is_x=False)
                sub_clip = sub_clip.set_position((sub_x, sub_y)).set_start(sub["start"])
                subtitle_clips.append(sub_clip)

        # ç»„åˆæ‰€æœ‰è§†é¢‘è½¨ï¼šèƒŒæ™¯è½®æ’­â†’å…¨å±€æ–‡å­—â†’æ°´å°â†’å­—å¹•
        all_clips = [bg_clip]
        if main_text_clip:
            all_clips.append(main_text_clip)
        if watermark_clip:
            all_clips.append(watermark_clip)
        all_clips.extend(subtitle_clips)
        final_clip = CompositeVideoClip(all_clips).set_audio(audio)

        # å¯¼å‡ºMP4è§†é¢‘ï¼ˆH264ç¼–ç ï¼Œå…¼å®¹æ€§å¼ºï¼‰
        output_path = os.path.join("temp_output", f"mv_{uuid.uuid4()}.mp4")
        final_clip.write_videofile(
            output_path, codec="libx264", audio_codec="aac",
            fps=15, threads=4, verbose=False, logger=None
        )

        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶ï¼Œé‡Šæ”¾èµ„æº
        audio.close()
        final_clip.close()
        for f in temp_files:
            try:
                os.remove(f)
            except:
                pass
        generated_video_path = output_path
        return output_path
    except Exception as e:
        # å¼‚å¸¸æ—¶ä¹Ÿæ¸…ç†ä¸´æ—¶æ–‡ä»¶
        for f in temp_files:
            try:
                os.remove(f)
            except:
                pass
        raise gr.Error(f"MVç”Ÿæˆå¤±è´¥ï¼š{str(e)}")


def download_video():
    """ä¸‹è½½ç”Ÿæˆçš„MV"""
    global generated_video_path
    if generated_video_path and os.path.exists(generated_video_path):
        return generated_video_path
    else:
        raise gr.Error("âŒ è¯·å…ˆç”ŸæˆMVåå†ä¸‹è½½ï¼")


# ===================== Gradioç•Œé¢ï¼ˆ3.0æœ€æ—©æœŸç‰ˆæœ¬å…¼å®¹ï¼Œæ— ä»»ä½•é«˜ç‰ˆæœ¬ç»„ä»¶ï¼‰ =====================
# æç®€CSSç¾åŒ–ï¼ˆé€‚é…ä½ç‰ˆæœ¬ï¼Œä»…ä¿ç•™åŸºç¡€å¥½çœ‹çš„æ ·å¼ï¼‰
custom_css = """
/* ä¸»æŒ‰é’®æ¸å˜ç¾åŒ– */
.gradio-container .button-primary {
    background: linear-gradient(135deg, #2a93b7 0%, #d94691 100%) !important;
    border: none !important;
    color: white !important;
    font-weight: 600 !important;
    border-radius: 6px !important;
}
/* æŒ‰é’®hoveræ•ˆæœ */
.gradio-container .button-primary:hover {
    opacity: 0.9 !important;
    box-shadow: 0 3px 8px rgba(0,0,0,0.1) !important;
}
/* æ‰€æœ‰è¾“å…¥æ¡†åœ†è§’ */
.gradio-container input, .gradio-container textarea, .gradio-container .slider {
    border-radius: 6px !important;
    border: 1px solid #e2e8f0 !important;
}
/* æ ‡é¢˜æ–‡å­—ç¾åŒ– */
.gradio-container h1 {
    color: #2a93b7 !important;
    font-weight: 700 !important;
    text-align: center !important;
    margin-bottom: 20px !important;
}
.gradio-container h2, .gradio-container h3 {
    color: #334155 !important;
    font-weight: 600 !important;
    margin-top: 15px !important;
}
/* æ•´ä½“å®¹å™¨å†…è¾¹è· */
.gradio-container {
    padding: 20px !important;
}
"""

# æ„å»ºåŸºç¡€ç•Œé¢ï¼ˆä»…ç”¨Tabs/Row/Column/åŸºç¡€ç»„ä»¶ï¼Œæ— ä»»ä½•é«˜çº§ç»„ä»¶ï¼‰
with gr.Blocks(title="ğŸ¤ AIç¿»å”±MVç”Ÿæˆå™¨ï¼ˆè½®æ’­ç‰ˆï¼‰", css=custom_css) as demo:
    # é¡¶éƒ¨ä¸»æ ‡é¢˜
    gr.Markdown("# ğŸ¤ AIç¿»å”±MVç”Ÿæˆå™¨ï¼ˆå¤šå¼ èƒŒæ™¯è½®æ’­ç‰ˆï¼‰")
    gr.Markdown("### âœ¨ æ ¸å¿ƒåŠŸèƒ½ï¼šå¤šå¼ èƒŒæ™¯å›¾è½®æ’­ | å­—å¹•ç²¾å‡†å±…ä¸­ | è¯­éŸ³æ®µè‡ªåŠ¨æ£€æµ‹ | æ—¶é—´è½´é˜²é‡å ")
    gr.Markdown("---")  # ç”¨markdownæ¨ªçº¿æ›¿ä»£Dividerï¼Œå…¼å®¹ä½ç‰ˆæœ¬

    # éšè—çŠ¶æ€å˜é‡ï¼šå­˜å‚¨è¯­éŸ³æ®µï¼ˆæ›¿ä»£å…¨å±€å˜é‡ï¼Œé˜²æ­¢æ•°æ®å åŠ ï¼‰
    voice_segments_state = gr.State(value=[])

    # æ ‡ç­¾é¡µï¼ˆä»…ç”¨åŸºç¡€TabItemï¼Œæ— iconï¼‰
    with gr.Tabs():
        # æ ‡ç­¾1ï¼šéŸ³é¢‘ä¸Šä¼ ä¸è¯­éŸ³æ£€æµ‹
        with gr.TabItem("éŸ³é¢‘è¯­éŸ³æ£€æµ‹"):
            gr.Markdown("## ğŸµ ä¸Šä¼ MP3éŸ³é¢‘å¹¶æ£€æµ‹è¯­éŸ³æ®µ")
            mp3_input = gr.Audio(label="ä¸Šä¼ ç¿»å”±MP3éŸ³é¢‘", type="filepath")
            detect_threshold = gr.Slider(
                label="è¯­éŸ³æ£€æµ‹é˜ˆå€¼ï¼ˆè¶Šå°è¶Šçµæ•ï¼Œæ‚éŸ³å¤šè°ƒè‡³0.03-0.04ï¼‰",
                minimum=0.01, maximum=0.1, value=0.02, step=0.01
            )
            detect_btn = gr.Button("ğŸ” å¼€å§‹æ£€æµ‹è¯­éŸ³æ®µ", variant="primary")
            voice_result = gr.Textbox(
                label="è¯­éŸ³æ£€æµ‹ç»“æœ", lines=6,
                placeholder="æ£€æµ‹ç»“æœå°†æ˜¾ç¤ºåœ¨è¿™é‡Œï¼Œä¼šåˆ—å‡ºæ‰€æœ‰è¯­éŸ³æ®µçš„èµ·æ­¢æ—¶é—´..."
            )
            gr.Markdown("---")

        # æ ‡ç­¾2ï¼šå­—å¹•è¾“å…¥ä¸æ—¶é—´è½´åŒ¹é…
        with gr.TabItem("å­—å¹•æ—¶é—´è½´ç”Ÿæˆ"):
            gr.Markdown("## âœï¸ è¾“å…¥çº¯å­—å¹•å¹¶åŒ¹é…è¯­éŸ³æ—¶é—´è½´")
            pure_subtitle = gr.Textbox(
                label="çº¯å­—å¹•æ–‡æœ¬ï¼ˆæ¯è¡Œä¸€æ®µï¼Œè¡Œæ•°ä¸è¯­éŸ³æ®µæ•°ä¸€è‡´ï¼Œæ— æ—¶é—´ï¼‰",
                lines=8,
                placeholder="ç¤ºä¾‹ï¼š\nç”Ÿæ´»å°±åƒä¸€æ¯æ¸…èŒ¶\nåˆå…¥å£æ—¶æˆ–è®¸æœ‰äº›è‹¦æ¶©\nä½†ç»†ç»†å“å‘³\nå´èƒ½æ„Ÿå—åˆ°å…¶ä¸­çš„ç”˜ç”œä¸æ¸…é¦™"
            )
            gr.Markdown("### â±ï¸ å­—å¹•æ—¶é—´å…¨å±€åç§»")
            with gr.Row():
                global_start_offset = gr.Slider(
                    label="å¼€å§‹åç§»ï¼ˆÂ±ç§’ï¼‰ï¼šè´Ÿæ•°=æå‰æ˜¾ç¤ºï¼Œæ­£æ•°=å»¶åæ˜¾ç¤º",
                    minimum=-1.0, maximum=1.0, value=0.0, step=0.1
                )
                global_end_offset = gr.Slider(
                    label="ç»“æŸåç§»ï¼ˆÂ±ç§’ï¼‰ï¼šè´Ÿæ•°=æå‰éšè—ï¼Œæ­£æ•°=å»¶åéšè—",
                    minimum=-1.0, maximum=1.0, value=0.0, step=0.1
                )
            match_btn = gr.Button("âš¡ ä¸€é”®åŒ¹é…è¯­éŸ³æ—¶é—´è½´", variant="primary")
            matched_subtitle = gr.Textbox(
                label="åŒ¹é…åçš„å¸¦æ—¶é—´è½´å­—å¹•ï¼ˆå¯æ‰‹åŠ¨å¾®è°ƒï¼‰", lines=10,
                placeholder="åŒ¹é…åå°†ç”Ÿæˆæ ‡å‡†æ ¼å¼ï¼šå¼€å§‹æ—¶é—´,å†…å®¹,ç»“æŸæ—¶é—´,å­—å·,é¢œè‰²,æ°´å¹³ä½ç½®,å‚ç›´ä½ç½®..."
            )
            gr.Markdown("---")

        # æ ‡ç­¾3ï¼šæ ¸å¿ƒåŠŸèƒ½ - å¤šå¼ èƒŒæ™¯è½®æ’­ + MVç”Ÿæˆ/ä¸‹è½½
        with gr.TabItem("MVç”Ÿæˆä¸å¯¼å‡º"):
            with gr.Row():
                # å·¦ä¾§ï¼šé…ç½®åŒºï¼ˆè½®æ’­/æ–‡å­—/æ°´å°ï¼‰
                with gr.Column(scale=2):
                    # èƒŒæ™¯è½®æ’­æ ¸å¿ƒé…ç½®ï¼ˆä½ çš„æ ¸å¿ƒéœ€æ±‚ï¼‰
                    gr.Markdown("## ğŸ–¼ï¸ å¤šå¼ èƒŒæ™¯å›¾è½®æ’­è®¾ç½®")
                    bg_imgs = gr.File(
                        label="ä¸Šä¼ å¤šå¼ èƒŒæ™¯å›¾ï¼ˆæ”¯æŒæ‰¹é‡é€‰æ‹©ï¼ŒJPG/PNGå‡å¯ï¼‰",
                        file_count="multiple", file_types=["image"]
                    )
                    slide_duration = gr.Slider(
                        label="å•å¼ å›¾ç‰‡æ˜¾ç¤ºæ—¶é•¿ï¼ˆç§’ï¼‰ï¼Œå›¾ç‰‡å¤šå»ºè®®è®¾1-2ç§’",
                        minimum=1.0, maximum=10.0, value=3.0, step=0.5
                    )
                    gr.Markdown("---")

                    # å…¨å±€æ–‡å­—é…ç½®
                    gr.Markdown("## ğŸ“œ å…¨å±€æ–‡å­—ï¼ˆè§†é¢‘å…¨ç¨‹æ˜¾ç¤ºï¼‰")
                    global_text = gr.Textbox(label="æ–‡å­—å†…å®¹", placeholder="AIç¿»å”±MV | è½®æ’­ç‰ˆ | å­—å¹•ç²¾å‡†å±…ä¸­")
                    global_text_size = gr.Slider(label="æ–‡å­—å¤§å°", minimum=10, maximum=100, value=30, step=1)
                    global_text_color = gr.ColorPicker(label="æ–‡å­—é¢œè‰²", value="#FFFFFF")
                    global_text_pos = gr.Textbox(
                        label="æ–‡å­—ä½ç½®ï¼ˆç¤ºä¾‹ï¼šcenter,80 æ°´å¹³å±…ä¸­+è·ä¸Š80px | right20,bottom50 å³ä¸‹20pxï¼‰",
                        value="center,80"
                    )
                    gr.Markdown("---")

                    # æ°´å°é…ç½®ï¼ˆå¯é€‰ï¼‰
                    gr.Markdown("## ğŸ”– æ°´å°è®¾ç½®ï¼ˆå¯é€‰ï¼Œå»ºè®®PNGé€æ˜èƒŒæ™¯ï¼‰")
                    watermark_img = gr.Image(label="ä¸Šä¼ æ°´å°å›¾ç‰‡", type="filepath")
                    wm_alpha = gr.Slider(label="æ°´å°é€æ˜åº¦", minimum=0.1, maximum=1.0, value=0.5, step=0.1)
                    wm_pos = gr.Textbox(label="æ°´å°ä½ç½®ï¼ˆç¤ºä¾‹ï¼šright20,bottom20ï¼‰", value="right20,bottom20")
                    gr.Markdown("---")

                    # æ“ä½œæŒ‰é’®
                    with gr.Row():
                        generate_btn = gr.Button("ğŸš€ ç”ŸæˆMV", variant="primary")
                        download_btn = gr.Button("ğŸ“¥ ä¸‹è½½MV")

                # å³ä¾§ï¼šå­—å¹•å¾®è°ƒ + é¢„è§ˆä¸‹è½½
                with gr.Column(scale=3):
                    gr.Markdown("## ğŸ¯ æœ€ç»ˆå­—å¹•é…ç½®ï¼ˆå¯æ‰‹åŠ¨ä¿®æ”¹æ—¶é—´/æ ·å¼ï¼‰")
                    final_subtitle = gr.Textbox(
                        label="æœ€ç»ˆå­—å¹•ï¼ˆåŒ¹é…åè‡ªåŠ¨åŒæ­¥ï¼Œå¯æ‰‹åŠ¨æ”¹ï¼‰",
                        lines=12, value=""
                    )
                    gr.Markdown("---")
                    gr.Markdown("## ğŸ¥ MVé¢„è§ˆä¸ä¸‹è½½")
                    video_output = gr.Video(label="ç”Ÿæˆçš„MVï¼ˆè½®æ’­èƒŒæ™¯+ç²¾å‡†å­—å¹•ï¼‰", height=400)
                    download_output = gr.File(label="ä¸‹è½½çš„MP4è§†é¢‘æ–‡ä»¶")

    # ===================== ç»‘å®šæ‰€æœ‰äº¤äº’äº‹ä»¶ï¼ˆåŸºç¡€ç»‘å®šï¼Œå…¼å®¹ä½ç‰ˆæœ¬ï¼‰ =====================
    # æ£€æµ‹è¯­éŸ³æ®µ
    detect_btn.click(
        fn=detect_voice_segments,
        inputs=[mp3_input, detect_threshold],
        outputs=[voice_result, voice_segments_state]
    )
    # åŒ¹é…å­—å¹•æ—¶é—´è½´
    match_btn.click(
        fn=match_subtitle_with_voice,
        inputs=[pure_subtitle, voice_segments_state, global_start_offset, global_end_offset],
        outputs=matched_subtitle
    )
    # åŒ¹é…åçš„å­—å¹•è‡ªåŠ¨åŒæ­¥åˆ°æœ€ç»ˆå­—å¹•æ¡†
    matched_subtitle.change(
        fn=lambda x: x,
        inputs=matched_subtitle,
        outputs=final_subtitle
    )
    # ç”ŸæˆMVï¼ˆæ ¸å¿ƒï¼šä¼ å…¥å¤šå¼ èƒŒæ™¯å›¾+è½®æ’­æ—¶é•¿ï¼‰
    generate_btn.click(
        fn=mp3_images_to_mp4,
        inputs=[mp3_input, bg_imgs, slide_duration, global_text, global_text_size, global_text_color,
                global_text_pos, watermark_img, wm_alpha, wm_pos, final_subtitle],
        outputs=video_output
    )
    # ä¸‹è½½MV
    download_btn.click(
        fn=download_video,
        inputs=[],
        outputs=download_output
    )

# ===================== å¯åŠ¨åº”ç”¨ + è‡ªåŠ¨æ¸…ç† + ä¾èµ–å®‰è£… =====================
if __name__ == "__main__":
    # è‡ªåŠ¨å®‰è£…ç¼ºå¤±ä¾èµ–ï¼ˆæ¸…åæºåŠ é€Ÿï¼Œè§£å†³ä¸‹è½½æ…¢/å¤±è´¥ï¼‰
    required_pkgs = ["gradio", "moviepy", "pillow", "librosa", "numpy"]
    for pkg in required_pkgs:
        try:
            __import__(pkg)
        except ImportError:
            print(f"æ­£åœ¨å®‰è£…ç¼ºå¤±ä¾èµ–ï¼š{pkg}")
            os.system(f"pip install {pkg} -i https://pypi.tuna.tsinghua.edu.cn/simple")

    # å¯åŠ¨GradioæœåŠ¡ï¼ˆæœ¬åœ°è®¿é—®ï¼Œç«¯å£7860ï¼‰
    print("âœ… æœåŠ¡å¯åŠ¨æˆåŠŸï¼Œæµè§ˆå™¨è®¿é—®ï¼šhttp://localhost:7860")
    demo.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False  # å…³é—­å…¬ç½‘åˆ†äº«ï¼Œä»…æœ¬åœ°ä½¿ç”¨
    )


    # ç¨‹åºé€€å‡ºæ—¶è‡ªåŠ¨æ¸…ç†æ‰€æœ‰ä¸´æ—¶æ–‡ä»¶ï¼Œé¿å…å ç”¨ç£ç›˜
    def cleanup_temp_files():
        for dir_name in ["temp_output", "temp_text", "temp_subtitles", "temp_audio", "gradio_temp"]:
            if os.path.exists(dir_name):
                try:
                    shutil.rmtree(dir_name)
                    print(f"âœ… å·²æ¸…ç†ä¸´æ—¶ç›®å½•ï¼š{dir_name}")
                except Exception as e:
                    print(f"âš ï¸  æ¸…ç†ä¸´æ—¶ç›®å½•å¤±è´¥ï¼š{e}")


    import atexit

    atexit.register(cleanup_temp_files)